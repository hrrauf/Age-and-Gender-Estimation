{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "import keras.preprocessing.image as kimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import metrics\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\n",
    "mat = scipy.io.loadmat('./data/wiki_crop/wiki.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"dob\", \"photo_taken\", \"full_path\", \"gender\", \"name\", \"face_location\", \"face_score\", \"second_face_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = mat['wiki'][0][0][0].shape[1]\n",
    "\n",
    "df = pd.DataFrame(index = range(0,instances), columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62328"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mat:\n",
    "    if i == \"wiki\":\n",
    "        current_array = mat[i][0][0]\n",
    "        for j in range(len(current_array)):\n",
    "            #print(columns[j],\": \",current_array[j])\n",
    "            df[columns[j]] = pd.DataFrame(current_array[j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>723671</td>\n",
       "      <td>2009</td>\n",
       "      <td>[17/10000217_1981-05-05_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Sami Jauhojärvi]</td>\n",
       "      <td>[[111.29109473290997, 111.29109473290997, 252....</td>\n",
       "      <td>4.300962</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>703186</td>\n",
       "      <td>1964</td>\n",
       "      <td>[48/10000548_1925-04-04_1964.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Dettmar Cramer]</td>\n",
       "      <td>[[252.48330229530742, 126.68165114765371, 354....</td>\n",
       "      <td>2.645639</td>\n",
       "      <td>1.949248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>711677</td>\n",
       "      <td>2008</td>\n",
       "      <td>[12/100012_1948-07-03_2008.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Marc Okrand]</td>\n",
       "      <td>[[113.52, 169.83999999999997, 366.08, 422.4]]</td>\n",
       "      <td>4.329329</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>705061</td>\n",
       "      <td>1961</td>\n",
       "      <td>[65/10001965_1930-05-23_1961.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Aleksandar Matanović]</td>\n",
       "      <td>[[1, 1, 634, 440]]</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>720044</td>\n",
       "      <td>2012</td>\n",
       "      <td>[16/10002116_1971-05-31_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Diana Damrau]</td>\n",
       "      <td>[[171.61031405173117, 75.57451239763239, 266.7...</td>\n",
       "      <td>3.408442</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  photo_taken                          full_path  gender  \\\n",
       "0  723671         2009  [17/10000217_1981-05-05_2009.jpg]     1.0   \n",
       "1  703186         1964  [48/10000548_1925-04-04_1964.jpg]     1.0   \n",
       "2  711677         2008    [12/100012_1948-07-03_2008.jpg]     1.0   \n",
       "3  705061         1961  [65/10001965_1930-05-23_1961.jpg]     1.0   \n",
       "4  720044         2012  [16/10002116_1971-05-31_2012.jpg]     0.0   \n",
       "\n",
       "                     name                                      face_location  \\\n",
       "0       [Sami Jauhojärvi]  [[111.29109473290997, 111.29109473290997, 252....   \n",
       "1        [Dettmar Cramer]  [[252.48330229530742, 126.68165114765371, 354....   \n",
       "2           [Marc Okrand]      [[113.52, 169.83999999999997, 366.08, 422.4]]   \n",
       "3  [Aleksandar Matanović]                                 [[1, 1, 634, 440]]   \n",
       "4          [Diana Damrau]  [[171.61031405173117, 75.57451239763239, 266.7...   \n",
       "\n",
       "   face_score  second_face_score  \n",
       "0    4.300962                NaN  \n",
       "1    2.645639           1.949248  \n",
       "2    4.329329                NaN  \n",
       "3        -inf                NaN  \n",
       "4    3.408442                NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datenum_to_datetime(datenum):\n",
    "    \"\"\"\n",
    "    Convert Matlab datenum into Python datetime.\n",
    "    :param datenum: Date in datenum format\n",
    "    :return:        Datetime object corresponding to datenum.\n",
    "    \"\"\"\n",
    "    days = datenum % 1\n",
    "    hours = days % 1 * 24\n",
    "    minutes = hours % 1 * 60\n",
    "    seconds = minutes % 1 * 60\n",
    "    exact_date = datetime.fromordinal(int(datenum)) \\\n",
    "           + timedelta(days=int(days)) \\\n",
    "           + timedelta(hours=int(hours)) \\\n",
    "           + timedelta(minutes=int(minutes)) \\\n",
    "           + timedelta(seconds=round(seconds)) \\\n",
    "           - timedelta(days=366)\n",
    "    \n",
    "    return exact_date.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_of_birth'] = df['dob'].apply(datenum_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "      <th>date_of_birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>723671</td>\n",
       "      <td>2009</td>\n",
       "      <td>[17/10000217_1981-05-05_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Sami Jauhojärvi]</td>\n",
       "      <td>[[111.29109473290997, 111.29109473290997, 252....</td>\n",
       "      <td>4.300962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>703186</td>\n",
       "      <td>1964</td>\n",
       "      <td>[48/10000548_1925-04-04_1964.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Dettmar Cramer]</td>\n",
       "      <td>[[252.48330229530742, 126.68165114765371, 354....</td>\n",
       "      <td>2.645639</td>\n",
       "      <td>1.949248</td>\n",
       "      <td>1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>711677</td>\n",
       "      <td>2008</td>\n",
       "      <td>[12/100012_1948-07-03_2008.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Marc Okrand]</td>\n",
       "      <td>[[113.52, 169.83999999999997, 366.08, 422.4]]</td>\n",
       "      <td>4.329329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>705061</td>\n",
       "      <td>1961</td>\n",
       "      <td>[65/10001965_1930-05-23_1961.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Aleksandar Matanović]</td>\n",
       "      <td>[[1, 1, 634, 440]]</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>720044</td>\n",
       "      <td>2012</td>\n",
       "      <td>[16/10002116_1971-05-31_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Diana Damrau]</td>\n",
       "      <td>[[171.61031405173117, 75.57451239763239, 266.7...</td>\n",
       "      <td>3.408442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  photo_taken                          full_path  gender  \\\n",
       "0  723671         2009  [17/10000217_1981-05-05_2009.jpg]     1.0   \n",
       "1  703186         1964  [48/10000548_1925-04-04_1964.jpg]     1.0   \n",
       "2  711677         2008    [12/100012_1948-07-03_2008.jpg]     1.0   \n",
       "3  705061         1961  [65/10001965_1930-05-23_1961.jpg]     1.0   \n",
       "4  720044         2012  [16/10002116_1971-05-31_2012.jpg]     0.0   \n",
       "\n",
       "                     name                                      face_location  \\\n",
       "0       [Sami Jauhojärvi]  [[111.29109473290997, 111.29109473290997, 252....   \n",
       "1        [Dettmar Cramer]  [[252.48330229530742, 126.68165114765371, 354....   \n",
       "2           [Marc Okrand]      [[113.52, 169.83999999999997, 366.08, 422.4]]   \n",
       "3  [Aleksandar Matanović]                                 [[1, 1, 634, 440]]   \n",
       "4          [Diana Damrau]  [[171.61031405173117, 75.57451239763239, 266.7...   \n",
       "\n",
       "   face_score  second_face_score  date_of_birth  \n",
       "0    4.300962                NaN           1981  \n",
       "1    2.645639           1.949248           1925  \n",
       "2    4.329329                NaN           1948  \n",
       "3        -inf                NaN           1930  \n",
       "4    3.408442                NaN           1971  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['photo_taken'] - df['date_of_birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove pictures does not include face\n",
    "df = df[df['face_score'] != -np.inf]\n",
    "\n",
    "#some pictures include more than one face, remove them\n",
    "df = df[df['second_face_score'].isna()]\n",
    "\n",
    "#check threshold\n",
    "df = df[df['face_score'] >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['name','face_score','second_face_score','date_of_birth','face_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some guys seem to be greater than 100. some of these are paintings. remove these old guys\n",
    "df = df[df['age'] <= 100]\n",
    "\n",
    "#some guys seem to be unborn in the data set\n",
    "df = df[df['age'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22578"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>723671</td>\n",
       "      <td>2009</td>\n",
       "      <td>[17/10000217_1981-05-05_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>[tensor(255.), tensor(255.), tensor(255.), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>711677</td>\n",
       "      <td>2008</td>\n",
       "      <td>[12/100012_1948-07-03_2008.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>[tensor(92.), tensor(97.), tensor(91.), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>720044</td>\n",
       "      <td>2012</td>\n",
       "      <td>[16/10002116_1971-05-31_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>[tensor(61.), tensor(30.), tensor(10.), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>716189</td>\n",
       "      <td>2012</td>\n",
       "      <td>[02/10002702_1960-11-09_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>[tensor(97.), tensor(122.), tensor(178.), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>707745</td>\n",
       "      <td>1971</td>\n",
       "      <td>[41/10003541_1937-09-27_1971.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>[tensor(190.), tensor(189.), tensor(194.), ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  photo_taken                          full_path  gender  age  \\\n",
       "0  723671         2009  [17/10000217_1981-05-05_2009.jpg]     1.0   28   \n",
       "2  711677         2008    [12/100012_1948-07-03_2008.jpg]     1.0   60   \n",
       "4  720044         2012  [16/10002116_1971-05-31_2012.jpg]     0.0   41   \n",
       "5  716189         2012  [02/10002702_1960-11-09_2012.jpg]     0.0   52   \n",
       "6  707745         1971  [41/10003541_1937-09-27_1971.jpg]     1.0   34   \n",
       "\n",
       "                                              pixels  \n",
       "0  [tensor(255.), tensor(255.), tensor(255.), ten...  \n",
       "2  [tensor(92.), tensor(97.), tensor(91.), tensor...  \n",
       "4  [tensor(61.), tensor(30.), tensor(10.), tensor...  \n",
       "5  [tensor(97.), tensor(122.), tensor(178.), tens...  \n",
       "6  [tensor(190.), tensor(189.), tensor(194.), ten...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram = df['age'].hist(bins=df['age'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['age'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of output classes:  101\n"
     ]
    }
   ],
   "source": [
    "classes = 101 #(0, 100])\n",
    "print(\"number of output classes: \",classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)\n",
    "\n",
    "def getImagePixels(image_path):\n",
    "    try:\n",
    "        img = image.load_img(\"./data/wiki_crop/%s\" % image_path[0], grayscale=False, target_size=target_size)\n",
    "        x = image.img_to_array(img).reshape(1, -1)[0]\n",
    "        \n",
    "        return torch.Tensor(x)\n",
    "        #x = preprocess_input(x)\n",
    "    except:\n",
    "        print(\"Data not found for the image \"+image_path)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pixels'] = df['full_path'].apply(getImagePixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(df.pixels.to_list(),\"images_torch.pt\")\n",
    "pd.DataFrame.from_dict(df).to_csv(\"age_gender_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= df['full_path'].iloc[0]\n",
    "img_size=(224,224)\n",
    "img = kimg.load_img(\"./data/wiki_crop/%s\" % path[0], grayscale=False, target_size=img_size)\n",
    "image = kimg.img_to_array(img).reshape(224, 224, 3)\n",
    "\n",
    "features=torch.Tensor(image).unsqueeze(0)\n",
    "\n",
    "for i in tqdm(range(1,df.shape[0])):\n",
    "    path= df['full_path'].iloc[i]\n",
    "    img = kimg.load_img(\"./data/wiki_crop/%s\" % path[0], grayscale=False, target_size=img_size)\n",
    "    image = kimg.img_to_array(img).reshape(224, 224, 3)\n",
    "\n",
    "    image_tensor=torch.Tensor(image).unsqueeze(0)\n",
    "\n",
    "    features=torch.cat((features,image_tensor), axis =0)\n",
    "    \n",
    "features=features.to(pytorch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['age'].values\n",
    "target_classes = keras.utils.to_categorical(target, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = df['pixels'].values\n",
    "features = []\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    features.append(df['pixels'].values[i])\n",
    "\n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features /= 255 #normalize in [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(features, target_classes\n",
    "                                        , test_size=0.30)#, random_state=42), stratify=target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-Face model\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-trained weights of vgg-face model. \n",
    "#you can find it here: https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "#related blog post: https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/\n",
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze all layers of VGG-Face except last 7 one\n",
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "base_model_output = Sequential()\n",
    "base_model_output = Convolution2D(classes, (1, 1), name='predictions')(model.layers[-4].output)\n",
    "base_model_output = Flatten()(base_model_output)\n",
    "base_model_output = Activation('softmax')(base_model_output)\n",
    "\n",
    "age_model = Model(inputs=model.input, outputs=base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check trainable layers\n",
    "if False:\n",
    "    for layer in model.layers:\n",
    "        print(layer, layer.trainable)\n",
    "    \n",
    "    print(\"------------------------\")\n",
    "    for layer in age_model.layers:\n",
    "        print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "age_model.compile(loss='categorical_crossentropy'\n",
    "                  , optimizer=keras.optimizers.Adam()\n",
    "                  #, optimizer = sgd\n",
    "                  , metrics=['accuracy']\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='classification_age_model.hdf5'\n",
    "    , monitor = \"val_loss\"\n",
    "    , verbose=1\n",
    "    , save_best_only=True\n",
    "    , mode = 'auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enableFit = False\n",
    "\n",
    "if enableFit:\n",
    "    epochs = 250\n",
    "    batch_size = 256\n",
    "\n",
    "    for i in range(epochs):\n",
    "        print(\"epoch \",i)\n",
    "        \n",
    "        ix_train = np.random.choice(train_x.shape[0], size=batch_size)\n",
    "        \n",
    "        score = age_model.fit(\n",
    "            train_x[ix_train], train_y[ix_train]\n",
    "            , epochs=1\n",
    "            , validation_data=(test_x, test_y)\n",
    "            , callbacks=[checkpointer]\n",
    "        )\n",
    "        \n",
    "        scores.append(score)\n",
    "    \n",
    "    #restore the best weights\n",
    "    from keras.models import load_model\n",
    "    age_model = load_model(\"classification_age_model.hdf5\")\n",
    "    \n",
    "    age_model.save_weights('age_model_weights.h5')\n",
    "        \n",
    "else:\n",
    "    #pre-trained weights for age prediction: https://drive.google.com/file/d/1YCox_4kJ-BYeXq27uUbasu--yz28zUMV/view?usp=sharing\n",
    "    age_model.load_weights(\"age_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_change = []; loss_change = []\n",
    "for i in range(0, len(scores)):\n",
    "    val_loss_change.append(scores[i].history['val_loss'])\n",
    "    loss_change.append(scores[i].history['loss'])\n",
    "\n",
    "plt.plot(val_loss_change, label='val_loss')\n",
    "plt.plot(loss_change, label='train_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and accuracy on validation set\n",
    "age_model.evaluate(test_x, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = age_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_indexes = np.array([i for i in range(0, 101)])\n",
    "apparent_predictions = np.sum(predictions * output_indexes, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = 0\n",
    "\n",
    "for i in range(0 ,apparent_predictions.shape[0]):\n",
    "    prediction = int(apparent_predictions[i])\n",
    "    actual = np.argmax(test_y[i])\n",
    "    \n",
    "    abs_error = abs(prediction - actual)\n",
    "    actual_mean = actual_mean + actual\n",
    "    \n",
    "    mae = mae + abs_error\n",
    "    \n",
    "mae = mae / apparent_predictions.shape[0]\n",
    "\n",
    "print(\"mae: \",mae)\n",
    "print(\"instances: \",apparent_predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model on a custom image\n",
    "\n",
    "Feed an image to find the apparent age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(filepath):\n",
    "    test_img = image.load_img(filepath, target_size=(224, 224))\n",
    "    test_img = image.img_to_array(test_img)\n",
    "    test_img = np.expand_dims(test_img, axis = 0)\n",
    "    test_img /= 255\n",
    "    return test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture = \"pacino.jpg\"\n",
    "#picture = \"brando.jpg\"\n",
    "#picture = \"katy-3.jpg\"\n",
    "\n",
    "prediction = age_model.predict(loadImage(picture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = np.arange(101)\n",
    "plt.bar(y_pos, prediction[0], align='center', alpha=0.3)\n",
    "plt.ylabel('percentage')\n",
    "plt.title('age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(picture)#, target_size=(224, 224))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(\"most dominant age class (not apparent age): \",np.argmax(prediction))\n",
    "\n",
    "apparent_age = np.round(np.sum(prediction * output_indexes, axis = 1))\n",
    "print(\"apparent age: \", int(apparent_age[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
